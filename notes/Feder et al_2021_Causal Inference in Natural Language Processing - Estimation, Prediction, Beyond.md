# 中文笔记 Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond

[TOC]

## Takeaways:

本文详细介绍了因果推断和NLP的融合，主要分为两个子方向：

 **NLP帮助因果推断**

文本作为因果推断的一个变量(treatment/outcome/confounder)，使用NLP方法对文本处理，从而对社会科学问题的因果分析。

- 因果推断需要满足可忽略性、正数性、一致性的假设。

- treatment：可设计随机实验，可忽略性和正数性自动满足，但需要注意一致性，保证样本之间的outcome不会互相影响，需要将开发measurement的样本与计算因果效应的样本分开来。

- confounder：不能设计随机实验，高维数据导致可忽略性和正数性都具有挑战。

- outcome：不能设计随机实验，三个假设都要注意是否被违反。


**因果推断帮助NLP**

传统NLP方法所面临的的OOD性能差、不同群体的算法公平性、不可解释等问题可以从因果的视角来解决。

- 增强鲁棒性：反事实数据增强 、分布准则约束（独立性准则、环境不变准则）、后门调整

- 因果视角下的算法公平性

- 因果视角下的解释：除了注意力、扰动、通过反事实的对比可以作为模型预测的解释。


## 0. 摘要

科学研究的一个基本目标是了解因果关系。然而，尽管因果关系在生活和社会科学中发挥着关键作用，但在 NLP 领域，却没有同样的重要性，传统上的 NLP 更强调预测任务。随着因果推理和语言处理融合的跨学科研究的兴起，这种区别正开始消失。然而，关于NLP中因果关系的研究仍然分散在各个领域，没有统一的定义、基准数据集和对现有挑战的清晰表述。

在这篇综述中，我们巩固了跨学术领域的研究，并将其置于更广阔的NLP领域中，为计算语言学界提供了一个统一的因果推理概述，主要分为两个模块的内容：

- NLP帮助因果：我们介绍了**估计因果效应**的统计挑战，包括**文本作为结果、治疗或混淆**的手段这三种设置。

- 因果帮助NLP：我们探索因果推理的潜在用途，以**改善NLP模型的性能、稳健性、公平性和可解释性**。


## 1. 介绍

很多科学领域都对**文本**作为数据来源很感兴趣，通常是用来评估政策干预的效果。这些领域强调因果推断，是NLP研究者所不熟悉的。

**因果推断**: 涉及一个通过干预制造的反事实世界问题：如果我们给一位病人施加了药物，他的病情进展会如何？在观察数据中，因果关系并不等同于相关关系。现在有大量关于使用传统数据集(非文本)进行有效因果推断的研究工作，但将这些技术应用于文本数据，面临着新的挑战。

**NLP**： 相反地，在经典的 NLP 应用中，目标是，很简单地做出准确的预测。任何统计相关都是可以被采纳的，不论其中的潜在的因果关系。然而，随着具有挑战的和高危领域的NLP系统的应用：

> - *训练集和数据集同分布假设不总成立；*
> - *对不可解释的黑盒预测模型不够满意；*

对于这两个问题，因果提供了一个有前景的路径：

> - 数据生成过程的因果结构（领域知识）能够提示推断偏差，帮助获得更加鲁棒的预测模型；
> - 对预测器本身的因果观可以为预测器的内部工作提供新的见解（因果解释）；
>

本篇综述的核心主张是：深入挖掘因果和NLP的连接，对促进社会科学研究者和 NLPers 的工作目标是有前景的。我们将该交叉领域分为两个不同的方面：

- **(1) NLP 帮助因果：从文本中估计因果效应**

> 例1： 一个在线论坛允许它的用户在他们的资料里用一个图标来表明他们的偏好性别。他们注意到，给自己贴上“女人”图标的用户，在他们的帖子上得到的“赞”往往更少。为了更好地评估他们允许在个人资料中提供性别信息的政策，他们提出了这样一个问题:被视为女性是否会导致一个帖子的人气下降?

例1是关于**被认为是女性**(treatment)对**帖子收到的赞**(outcome)的因果效应。这个反事实问题是:如果我们可以操纵一个帖子上的性别图标，这个帖子会收到多少个赞?

观察到的**被视为女性**和**获得更少的赞**之间的相关性通常与因果效应不一致（人类的因果直觉上，我们认为这个相关性应该没那么强）。这是因为相关性的出现有两个可能的原因:

- 真正的因果效应
- 由混杂因素(与治疗和结果都相关的变量)引起的虚假相关

在这个例子中，一个帖子的主题很可能是一个混淆因素：带有女性图标的帖子可能更多地是关于某个话题，而那个话题可能不会得到那么多的赞。section 2, 我们将看到，**由于混淆，没有假设就不可能估计因果效应。**

例1强调文本编码了因果效应中的confounder, 文本数据还可以对outcome 或感兴趣的treatment进行编码。比如说，我们想知道感知性别是怎么影响一条博文所收到回复文本的情感的（outcome），或者我们想知道写作风格是如何影响点赞数的(treatment)。文本数据的因果推理涉及几个不同于典型因果推理设置的挑战:

文本是高维的，需要**复杂的建模**来度量语义上有意义的因素，如主题，并需要仔细思考如何形式化因果问题对应的干预。从主题模型到上下文嵌入，自然语言处理在建模语言方面的发展为从文本中提取所需信息以估计因果效应提供了有前景的方法，然而，我们需要**新的假设**，以确保使用NLP方法导致有效的因果推理。我们将在第3节讨论从文本中估计因果效应的现有研究，并强调这些挑战和机遇。

- **(2) 因果帮助 NLP：用因果形式使NLP方法更加可靠**

> 例2：一家医学研究中心希望建立一个分类器，从病人医疗记录的文本叙述中检测临床诊断。这些记录汇总在多个医院站点，目标临床状况的频率和叙述的写作风格都有所不同。当分类器应用于不属于训练集的站点的记录时，它的准确率会下降。事后分析表明，它在虚假相关的特性上投入了大量的精力，比如格式化标记。

例2 同样涉及一个反事实的问题：如果我们保持临床状态不变，改变医院地址的话，分类器的预测会改变吗？

我们想让分类器依赖表达临床事实的短语，而非写作风格。然而，在训练数据里，由于地址是一个混杂变量，临床条件和写作风格是虚假相关的：一家医院，因为它的位置或其他特殊性，可能更容易遇到某诊断目标，该医院也可能使用独特的文本特征，如在每个叙述的开头使用样板文本。在训练集中，这些特性将是标签的预测，但它们不太可能在新医院场景中有用。在本例中，医院地址就像一个混杂因子，它在文本的某些特征和预测目标之间创建了虚假的相关性。

例2 证明了缺乏鲁棒性使得NLP方法**缺乏信任度**。此外，NLP系统通常是**黑盒模型**，这使得人们很难理解文本的可解释特征是如何导致观察到的预测的。为了解决NLP方法所面临的的鲁棒性和可解释性挑战，我们需要新的准则来学习探索相关关系以外的模型。

例如，我们希望预测器对于我们对文本所做的某些更改是不变的，例如在保持ground truth标签不变的情况下更改格式。**利用因果关系来发展新的准则**，为建立可靠的、可解释的自然语言处理方法提供服务，这是相当有希望的。与文本因果推理的研究领域相比，尽管最近的经验成功很好地推动了这一领域的研究，因果关系和NLP研究的这一领域较少被理解。在第四部分，我们涵盖了现有的研究，并回顾了使用因果关系来改进自然语言处理的挑战和机遇。



## 2. 背景

本研究的两个焦点问题(因果效应估计和因果驱动NLP)均涉及因果推理。因果推理的关键因素是在干预的基础上定义反事实。

例1涉及在线论坛的帖子 $W$​​ 和他们收到的点赞数量 $Y$​​。为了便于解释，我们使用一个二元变量 $T$​​ 来表示一个帖子的作者是否使用了“女性图标”。理想情况下，我们希望对变量 $T$​​ 进行干预，称为治疗。反事实的结果 $Y(1)$​​ 表示如果我们对某博文使用女性图标，帖子将收到的赞数。反事实结果 $Y(0)$​​​ 的定义类似。

<img src="imgs\image-20211012115534822.png" alt="image-20211012115534822" style="zoom:80%;" />

因果推理的基本问题是，**我们永远无法同时观察一个博文的反事实结果，不可能同时对治疗进行干预和观察结果。**这个问题使得因果推理比统计推理更难，没有假设的话不可能完成因果推理。

例2包含一个训练好的分类器 $Y' (W)$ ，它以临床叙述 $W$ 作为输入，输出诊断预测。 $W$ 是根据医生的诊断 $Y$而写的文本，也受医院地址 $Z$ 所引起的写作风格的影响。我们想要干预 $Z$ ，同时保持固定的标签 $Y$。反事实的叙述 $W(z)$ 是我们将会有的文本我们将医院设置为 $z$ 值，同时保持诊断不变。反事实预测 $Y~'(W(z))$​ 是训练好的分类器在给定反向量的情况下产生的输出。

<img src="imgs\image-20211012115613765.png" alt="image-20211012115613765" style="zoom:80%;" />

### 2.1 反事实查询

基于已定义的反事实，分析人员必须指定涉及反事实分布的感兴趣的量。例1中，感兴趣的因果效应是平均治疗效应(ATE)，
$$
ATE = E[Y (1)] - E[Y (0)]  \ \ \ \ (1)
$$
公式1表示，如果我们可以干预改变帖子作者的性别时，帖子收到的反事实点赞的平均差异。例2涉及更多的反事实问题，它们将在第4部分进行解释。

### 2.2 因果图模型

因果推理需要**假设**来**识别反事实查询**（将它们表达为观察结果的函数）。因此，我们需要对我们的世界模型进行编码，以验证模型是否满足做出因果推理所需的假设。我们可以使用因果有向无环图(因果DAG)来阐明我们的世界模型。在一个因果DAG，从变量 $X$ 到变量 $Y$ 的边意味着改变 $X$ 的值可能会改变 $Y$ 的分布。我们在变量之间使用双向虚线箭头表示它们是相关的。

<img src="imgs\image-20211008110350906.png" alt="image-20211008110350906" style="zoom:80%;" />

图1说明了示例1和示例2的假设因果关系DAG。在例1中，作者选择的性别图标( $T$ ​)与帖子的属性( $W$ )相关，这两个变量都会影响帖子收到的赞数($Y$)。在例2中，诊断($Y$)和医院($Z$)是相关的，两者都影响临床叙述(W)的文本。然后，经过训练的分类器根据文本 $W$ 进行预测 $Y~'$​​​.

因果DAG包含变量之间的所有统计相关性。例如，在图1的右DAG中，对于每个叙述 $W$​​，预测 $Y~'$​​并非独立于医院$Z$​​​ 。我们可以使用D分离算法找到这样的依赖关系(Pearl, 1994)。正如我们将在下面看到的，这些陈述允许我们检查因果DAG是否满足因果推理所需的一些假设。

### 2.3 因果推断的假设

我们将集中在例1来解释因果推理所需的假设。具体来说，我们将回顾一些假设，使得我们可以使用方程(1)来计算ATE。尽管我们关注ATE，但所有因果推理（不止是计算ATE的时候）都需要以某种形式进行相关假设，换句话说，这些条件成立，我们才可以将观察性研究视为条件随机试验。

1. [可忽略性](https://zhuanlan.zhihu.com/p/356635697)

   可忽略性是最重要也是最难证明的假设。它要求treatment assignment独立于counterfactual outcome。

   <img src="imgs\image-20211012121014015.png" alt="image-20211012121014015" style="zoom:80%;" />

   随机分配实验是一种满足可忽略性的方式，但有时不可行。在观察性的研究里，所以我们需要**有条件的可忽略性**对观察性研究的数据。也就是说，给定一组变量（后门准则）的情况下，treatment assignment独立于counterfactual outcome。

   <img src="imgs\image-20211012120841995.png" alt="image-20211012120841995" style="zoom:80%;" />

   > （我关于独立的理解）
   >
   > <img src="imgs\image-20211012123201643.png" alt="image-20211012123201643" style="zoom: 67%;" />
   >
   > 也就是说，没有后门路径传播虚假的因果效应，这样计算的ATE才有效。

   我们可以使用因果关系DAG根据后门准则（一种由d分离衍生出的算法）获取所有必要的混杂变量，对于例1，将博文 $W$ 本身作为混杂变量满足条件可忽略性。条件忽略性可能看起来像一顿免费的午餐，但**它要求不存在未被观察到的混杂因素**，这是研究者必须仔细评估的强假设。

2. 正数性

   在控制了 $X$​ (混杂变量) 的基础上，任一治疗的取值（在某种条件下）的概率都应该大于0.
   $$
   0<\operatorname{Pr}(T=1 \mid X=x)<1
   $$
   如果不满足会有什么情况？我们就没办法模拟在某个性别 $x$​​​​​ 下，服药组的反事实结局。正数性将帮助我们把反事实世界联系到观测数据。

   > 下例来自《causal inference: what if》p31
   >
   > <img src="imgs\image-20211012130028905.png" alt="image-20211012130028905" style="zoom:80%;" />

   

3. 一致性

   一致性要求我们的治疗方式是well-defined， 并且能与我们数据中的治疗方式相对应。一致性意味着我们观测到的治疗组每个被试的结局， 等于这个被试如果接受了治疗时的反事实结局； 我们观测到的非治疗组每个被试的结局，等于这个被试如果未接受治疗时的反事实结局。什么时候一致性会不成立呢？毕竟，如果我服用了阿司匹林（ A =1） ， 然后我死了（ Y =1）， 不是就说明我的反事实结局 $Y^{a=1}$​​​​就是 1？ 因而许多人认为一致性非常简单。 但这种表明上的“简单”具有很强的欺骗性。   

   一致性将反事实的结果与观察到的结果联系起来，需要满足两点:

   （1）不存在干扰: 样本i的结果只受样本i的处理状态的影响，而不受其他样本的处理状态的影响。

   （2）治疗方法需要指明（只存在一种治疗形式）。如果同一治疗的不同形式有不一样的因果效应， 那问题就会随之产生。 在例1中，这意味着**感知到的性别**是一个帖子收到点赞的关键，我们干预改变性别认知的方式——无论是操纵图标还是改变用户名——都不会改变与事实相反的结果。在观察性研究中，研究者只能尽可能精确地去定义研究中的干预措施，劣定的措施会使我们对因果效应估计值的阐释模糊不清，但是足够良定的干预措施在我们的现实数据中又不存在的话， 也会使我们的因果推断不清不楚，会导致有一些个体的反事实结局和观测结局的一致性不存在（也可以理解为正数性）。  

## 3. 从文本中估计因果关系

### 3.1 文本作为 Outcome

<img src="imgs\image-20211012134530960.png" alt="image-20211012134530960" style="zoom:80%;" />

可设置**随机实验**进行因果推断。文本可以自然地作为随机实验的结果，在随机实验中，受试者会产生开放式的反应。核心挑战是将高维文本数据提取成一些低维的感兴趣的特征。

**随机实验可以保证可忽略性和正值性**，但无法保证**一致性**。首先我们要保证参与实验的学生互不影响；其次，在进行研究之前，研究人员需要创建结果的测量标准，例如可读性。

然而，这个衡量通过样本开发出来的话，一个观察的处理状态可能会通过衡量模型影响另一个观察的结果。分割样本或顺序实验可以有效地解决这些问题，测量方法是在数据的一批样本上开发，完成后才估计其余数据的因果效应。

### 3.2 文本作为 Confounder

![image-20211012134717729](imgs\image-20211012134717729.png)

考虑一个学术文章第一作者性别与其被引用数量的因果效应，其中论文的主题是混杂因子。只有观测数据，只能进行观察性研究。

文本作为混杂的挑战是使用NLP方法阻止混杂。

1. 一种方法是应用**无监督降维**方法，将高维文本数据降为一组低维变量。这些方法包括潜在变量模型，如主题模型、嵌入方法和自动编码器。Roberts等人(2020)和Sridhar和Getoor(2019)应用主题模型，从文本数据中提取混淆模式，并对这些推断变量进行调整。Mozer等人(2020)直接基于词袋表示上的距离度量进行匹配。
2. 第二种方法是使用**监督模型**。最近，Veitch等人(2020)采用了预训练语言模型和监督主题模型来预测治疗和结果。通过学习能很好地预测治疗和结果的低维变量，他们表明，在文本数据中可以发现混淆特征。Roberts等人(2020)将这些策略与主题模型方法结合在文本匹配框架中。

因为文本作为混杂应用于**只有观测数据可用的设置**，为了调整混杂，NLP需要特别**强可忽略性的假设**——混杂的所有方面都必须通过模型来衡量。这对于高维数据尤其具有挑战性，因为随着我们所需要的变量数量的增长，要满足正数性变得越来越困难。我们可能会不小心以对撞变量为条件，而导致一个微妙的问题，即打开一个本应关闭的后门路径。Keith等人(2020)对这一快速发展的研究领域进行了概述，并对许多推论面临的威胁进行了更深入的研究。

### 3.3 文本作为 Treatment

<img src="imgs\image-20211012152605770.png" alt="image-20211012152605770" style="zoom:80%;" />

在文本作为治疗问题时，我们感兴趣的是语言对下游决策、行为和其他结果的因果关系。研究人员通常感兴趣的是**文本的特定方面**是如何导致这些结果的。例如，“请投票”广告的写作风格是否会让读者投票?

（1）研究文本效应的一种方法涉及**治疗发现**:

产生可能与结果有因果关系的可解释文本特征——例如**主题**和**其他潜在影响维度**或**词汇特征**，如n-gram。例如，Fong and Grimmer  发现了候选人传记的特征，推动了选民的评价。Pryzant et al(2017)发现营销材料中的写作风格对增加销售数字有影响，Zhang等人(2020b)发现会话倾向导致积极的心理健康咨询对话。

（2）另一种方法是**估计从文本中提取的特定属性的因果效应**：

Gerber等人(2008)研究了**呼吁公民投票义务**对投票率的影响。在这种情况下，**因素是文本的潜在属性**，为此我们需要一个测量模型。

作为治疗设置的文本对因果推理提出了几个独特的挑战：

（1）首先，由于人们选择他们阅读的文本的原因与兴趣的结果相关，**可忽略性通常是违反的**。为了克服这个问题，Fong和Grimmer(2016, 2021)给读者随机分配文本。Pryzant等人(2020)在不可能随机分配文本属性时，估计文本属性的影响，但要求文本包含所有混杂因素这个强烈的假设。如果有未观察到的原因影响人们阅读的文本和他们的结果(例如，他们的政治派别)，可忽略性假设是违反的。

（2）文本作为treatment的第二个独特挑战涉及**正数性**。假设我们想估计礼貌程度对电子邮件回复时间的因果影响。即使正文包含了所有的混淆因素(例如，主题，语气，写作风格)，也无法想象一封礼貌的电子邮件包含了某种特定的写作风格(例如，亵渎)。

（3）文本作为治疗的最后一个挑战与**一致性**问题有关: 为了做出有效的推断，我们需要**在不同的数据中开发我们的测量方法**，而不是我们用来估计因果效应的数据。

### 3.4 Opportunities

NLP研究人员有很多机会可以通过NLP方法促进因果推理，我们强调了从文本数据中进行因果推理的关键挑战：

**Heterogeneous effects**  

不同的人对文本有不同的解读。这给解释因果效应和交流研究结果带来了一些问题。例如，当文本作为治疗手段时，同样的文本可能对不同的人产生不同的影响，部分原因是每个人对文本的理解都是不同的。用文本构建和识别异质因果效应将需要新的反事实问题、假设和方法。

**benchmark**

基准数据集通过创建可评估预测模型的指标，推动了机器学习向前发展。虽然因果解释领域的基准在不断增长(见§4.3)，但因果效应估计的NLP数据集仍然欠缺(Feder等人，2021年)。这是因为，与事实相反的潜在结果从定义上来说是不可观测的——任何假定反事实知识的基准数据集，必然是对数据生成过程做出了一个不可验证的强烈假设。虽然我们可以将总体结果与实验进行比较，但我们永远无法观察到一个真正的因果效应。

## 4. 利用因果形式体系提高 NLP 方法的可靠性

那么如何使用因果推理来帮助解决传统的NLP任务呢？如理解、操作和生成自然语言。

神经网络不试图识别因果关系，一个特征可能是一个强大的预测器，即使它与期望的输出没有直接的因果关系。尽管可以达到很好的效果，但是相关性的预测模型是不容信赖的，而这些缺点都可以通过因果的思维来解决:

- 他们可能会抓住虚假的相关性(“捷径”)，导致在out- of-distribution (OOD)设置中出现错误(例如，McCoy et al.，2019); 观测和标签之间因果关系的先验知识可用于形式化这种虚假相关，并减轻模型对它们的依赖(Bühlmann, 2020; Veitch等人，2021年);
- 它们可能在不同用户群体之间表现出不可接受的性能差异，呈现出social bias(例如，Zhao et al.， 2017);因果关系也为算法公平性提供了一种语言(Kilbertus等人，2017年)。
- 他们的行为可能太难以理解，无法纳入高风险决策(Guidotti et al.， 2018)。解释预测的任务可能会自然地用反事实来表述(Feder等，2021年)。

由于这些原因，越来越多的研究试图围绕因果重新定位机器学习。到目前为止，应用主要集中在其他领域，如:**生物医学数据**，其中可信度是特别重要的(如Muandet等人，2013)；还有**计算机视觉**领域，CV领域相对容易构建具有人工虚假相关性的数据集。

在本节中，我们回顾将因果思想应用于自然语言处理的工作，重点关注出现的独特挑战。

### 4.1 学习鲁棒的预测器

NLP领域越来越关注虚假相关性。当满足两个条件时，就会出现虚假的相关性。

1. 在训练数据中必须有一些关于特征 $X$ 和标签 $Y$ 的信息因子 $Z$

2. $Y$ 和 $Z$ 必须依赖于训练数据，但不能保证在一般情况下保持

问题是预测器 $f: X \rightarrow Y$​ 将学习使用带有关于 $Z$ 的信息的 $X$ 部分(因为 $Z$ 提供了关于 $Y$ 的信息)，但是在应用模型时，学到的 $X$ 和 $Y$ 的这些部分之间的关系不需要保持。

虚假相关性也出现在广泛使用的公开 NLP 任务中，如自然语言推理，其中否定词与语义矛盾相关。这种相关性是虚假的，因为它产生于众包过程中的标注习惯，注释者在被要求写出一个矛盾句子时，使用否定词的倾向很大，这种模式不适用于在更自然的条件下产生的文本。这些观察结果导致对评估方式提出新的建议，以确保预测指标不是 “right for the wrong reasons  ”。

这些评价通常采取两种形式:

**不变性测试，**评估预测是否受到与标签无关的扰动的影响。预测结果不变，证明模型没有把错误的线索当成预测的依据。不变性测试可以由因果直觉驱动，目的是测试预测器在反事实输入 $X(Z = \tilde Z)$​上的行为是否不同，其中 $Z$​ 标记了研究者认为与  $Y$​​ 无关的文本的原因。

**敏感性测试，**应用的扰动在某种意义上应该是翻转真实标签所需的最小变化。预测结果反转，证明模型有把正确的线索当成预测的依据。同样，敏感性测试也是由因果直觉驱动，可以视为对反事实 $X(Y = \tilde Y)$​ 的评估，其中标签改变了，但对 $X$​​​​ 的所有其他因果影响保持不变(Kaushik等人，2020)。

已经提出了许多方法来学习通过灵敏度和不变性测试的预测器。这些方法中有许多或明或暗地受到因果观点的驱动；它们可以被视为将数据因果结构的领域知识纳入学习目标的方法。现在我们将这些方法分为两大类:反事实数据增强和基于因果驱动的分布准则。

#### 4.1.1 数据增强

要了解通过不变性和敏感性测试的预测器，一个直接的方法是数据增强：引出或构建反事实的实例，并将它们纳入训练数据中。在不变性测试的情况下，可以通过在学习目标中添加一惩罚项来提供额外的关注，以明确惩罚反事实对预测中的分歧，$e.g., |f(X(Z = z)) - f(X(Z = \tilde z))|$​。在对标签 $Y$ 进行干预的情况下，对标签反事实  $X(Y = ~\tilde Y)$​​​ 进行训练，可以提高ood的泛化能力，降低对噪声的敏感性。

反事实样本可以通过以下几种方式产生:

**(1) manual post-editing**  通常流利和准确，但相对昂贵。

**(2) heuristic replacement of keywords**   基于关键字的方法在某些情况下是合适的——例如，当可以通过局部替换封闭类词汇(如代词)来获得反事实时——但它们不能保证流利性或覆盖所有标签和感兴趣的协变量，跨语言推广困难。

**(3) automated text rewriting**   完全生成方法可以潜在地将手工编辑的流畅性和覆盖面与词汇启发式的简单性结合起来，但这些方法仍然相对不成熟。

反事实样本是一种强大的资源，因为它们直接解决了因果推理所固有的缺失数据问题。然而，存在两个问题：

- **有意义的反事实很难生成：**在很多情况下，即使是人类也很难提出有意义的反事实，比如，把一篇书评转换成一篇餐厅评论，同时保持“其他一切”不变的任务。
- **反事实的产生引入新的虚假相关**：例如，当要求重写 NLI任务的反事实而不使用否定时，标注者(或自动文本重写器)可能会找到另一个捷径，引入新的虚假关联。同样，如果关键词词汇不完整，关键词替代方法可能会引入新的虚假相关性(Joshi 和He, 2021)。

#### 4.1.2 分布规则

反事实数据增强所面临的问题激发了直接对观测数据进行操作的方法的出现。在不变性测试的情况下，一种策略是推导不变性预测器的分布性质，然后确保训练的模型满足这些性质。

（1）独立性准则

Veitch等人(2021)表明，反事实不变预测将满足可以从数据生成过程的因果结构中推导出来的独立性准则。

<img src="imgs\image-20211012115613765.png" alt="image-20211012115613765" style="zoom:80%;" />

例如，考虑上面的医疗记录示例，它具有虚假的特征(方言) $Z$​ 和标签(诊断) $Y$​。“改变方言不应改变诊断”的认知可以形式化为对 $Z$​ 的反事实不变性: the predictor $f$​ should satisfy $f(X(z)) = f(X(z~'))$​ for all $z$​, $z~'$​.  在本例中，$Z$​ 和 $Y$​ 都是产生文本特征 $X$​ 的原因 。利用这一观察结果，可以证明任何反事实不变预测器都能满足：

<img src="imgs\image-20211009155208915.png" alt="image-20211009155208915" style="zoom:80%;" />

也就是说，预测 $f(X)$ 独立于协变量 $Z$，给定真实标签 $Y$。

例如，考虑版主将论坛评论 $X$ 标记为有毒(或无害) $Y$ ，假设有毒的评论倾向于(在训练中)有强烈的负面情绪 $Z$​​​。在这种情况下，可以证明一个反事实不变的预测器将满足：

<img src="imgs\image-20211009155208915.png" alt="image-20211009155208915" style="zoom:80%;" />

在这种方式下，关于问题因果结构的知识可以用来推导反事实不变性的观测数据特征。这种特征可以作为正则化术语合并到训练目标中(例如，使用基于核的统计依赖度量)。这些标准不能保证反事实不变性，但在实践中，它们增加了反事实的不变性，并且，在不要求分析人员生成反事实样本的情况下，提高了 OOD 测试集上的性能。

（2）环境不变准则

通过将训练数据视为由有限的环境集产生的，可以推导出另一组分布准则，在这些环境中，每个环境都被赋予了一个不同的分布，但 $X$​ 和 $Y$​​ 之间的因果关系在环境中是不变的。这激发了一组环境不变标准:

- 预测器应该包括一个跨环境不变的表示函数；

- 我们应该归纳出这样一种表示，即相同的预测器在每个环境中都是最优的；

- 预测器应该在不同的环境中同样被很好地校准。

多环境训练在概念上类似于 domain adaptation ，但这里的目标不是学习任何特定目标领域的预测器，而是学习在一组具有因果共性的领域(称为领域泛化)中工作良好的预测器。

（3）后门调整

控制 $Y$​ 和 $Z$​ 之间混淆的第三种方法是估计$P (Y |X;Z)$​​，然后通过对 $Z$ 的值求和来计算一个预测分布:

<img src="imgs\image-20211012120932810.png" alt="image-20211012120932810" style="zoom:80%;" />

以边际 $P(Z)$​​ 加权而不是 $P (Z|X)$​​。当标签 $Y$​​ 是由文本 $X$​​ 引起的，而 $Z$​​​ 是混淆的，这种因子分解与将观测概率转换为干预概率的“后门调整”密切相关。Landeiro 和 Culotta (2018)将该思想应用到文本分类中，证明了对人工的虚假相关引起的 domain shifts  的鲁棒性。

一般来说，与典型的监督学习设置相比，这些方法需要更丰富的训练数据：要么用显式标签 $Z$​​​ 表示不应影响预测的文本原因，要么访问从多个环境中收集的数据。获取此类数据是否比创建反事实的实例更容易，取决于具体情况。此外，分布方法迄今只应用于分类问题，而数据增强可以应用于更结构化的问题，如机器翻译。因此，关于分布准则的未来工作须解决结构化预测问题，以及补充的标注样本是有噪的或者近似的这种情况（我的理解是：反事实样本不够完美的情况）。

未来的工作还应考虑使用不完全因果模型的后果，例如，未观察到的混淆。一般来说，未观察到的混淆对因果推理是一个挑战，但它可能在语言应用中普遍存在，因为在这种应用中，文本产生于作者表达语义概念的结构化安排的意图，而标签对应于一个查询，或者是直接针对预期的语义产生的查询，或者在读者可能理解的语义上产生的查询（我的理解是：自然语言是人类自发产生的，类比对照实验中病人自动选择服药，会有未被观察到的混淆，比如，有可能选择服药的更倾向于是女性）。

### 4.2 公平性与偏置

NLP系统继承并放大文本训练数据中编码的不受欢迎的social bias(Barocas等，2019;Blodgett等人，2020年)。在这里，因果关系也可以提供一种语言，通过种族和性别等人口属性来指定所需的公平条件：

- Hardt等人(2016)表明，需要进行因果分析，以确定观察到的数据分布和预测是否引发了公平性问题；
- Kilbertus et al(2017)表明，公平指标可以由数据生成过程的因果解释驱动;
- Kusner等人(2017)研究了“反事实公平”预测器，对每个个体来说，预测结果和改变其受保护属性之后的而产生的反事实版本的预测结果是一样的。

然而，将种族等属性作为受干预或反事实推理影响的变量，存在一些重要的合法性问题，Kilbertus等人(2017)提议，可转而关注可观察的代理变量(如：姓名)的不变性，而不是种族本身。

因果关系和不公平偏见之间的基本联系主要是在相对低维的表格数据而不是文本的背景下探讨的。然而，在这种情况下，§4.1.1中的反事实数据增强策略有几个应用:例如，Garg等人(2019)通过交换“身份项”列表来构建反事实，目的是减少文本分类中的偏见；赵等(2018)改变”性别标记“，如代词和名称，构建反事实样本以实现指代消解。反事实数据增强也被用于减少预先训练的上下文化词嵌入模型的偏差，但是，预先训练过的模型中的偏差会在多大程度上传播到下游应用程序尚不清楚。§4.1.2中讨论的分布准则，在算法公平性中的应用相对较少，但是Adragna等人(2020年)表明，不变风险最小化(Arjovsky等人，2019年)——试图在多个“环境”中学习不变预测器——可以减少在Civil Comments 数据集(Borkan等人，2019年)中对种族与毒性标签之前虚假相关性的捕捉。

### 4.3 因果模型解释

众所周知，NLP模型很难解释，但它对诊断错误和与决策者建立信任至关重要。

- 注意力

  产生解释的一个重要方法是利用网络构件，如注意力权重(Bahdanau et al.， 2014)，它是在生成预测的路径上计算的(例如，Xu et al.， 2015;Wang et al.， 2016)。基于注意力的解释可能会产生误导(Jain和Wallace, 2019)，通常只可能针对单个单元，他们不能用更抽象的语言概念来解释预测。

- 扰动

  也有人尝试通过对测试样本或者它们的隐藏表示扰动来估计更简单和更可解释的模型。现有的基于扰动的方法往往产生 implausible 的反事实，也不允许估计句子级概念的影响。

- 反事实解释

  作为一个因果推理问题，一个自然的解释方法是**生成反事实**的例子(见§4.1.1)，然后比较每个例子的预测和它的反事实样本（预测结果不同）。这样的控制设置类似于§2中描述的随机实验，在这个实验中，可以计算实际观察到的文本与没有特定概念的文本之间的差异。事实上，在可以生成反事实文本的情况下，我们通常可以估计基于文本的模型的因果效应。然而，自动生成自然语言反事实往往很难，手工生成成本太高，特别是对于抽象概念，如语言风格、主题或情感。

  为了克服反事实生成问题，另一类方法提出**操纵文本的表示**而不是文本本身。这些解决方案与鲁棒性文献中的方法有相似之处(例如，Muandet et al.， 2013)，但重点是**识别已训练的模型中的不变性**，而不是在训练期间强制执行它们。

  与其使用反事实来识别不变性，一种互补的方法是用最小的变化生成反事实，从而获得不同的模型预测（Wachter et al.,2017; Karimi et al., 2021; Mothilal et al., 2020  ）。这些例子可以作为解释，因为它们让我们观察到改变模型预测所需的变化。

  最后，还有一个针对前面提到的基于注意解释的因果视角，那就是将内部节点视为从输入到输出的因果效应的中介因子，通过使用手工制作的反事实查询模型，我们可以观察信息如何在不同的模型组件中流动，并确定它在模型中的何处被编码的。

## 5 结论

本综述的主要目的是将因果关系和NLP的各种交叉点收集到一个空间，我们将其细分为：统计因果推理问题和传统NLP任务。这些分支具有共同的目标和直觉，并开始显示出方法上的协同作用。在第3节中，我们展示了最近NLP建模方法可以帮助研究人员利用文本数据得出因果结论，在第4节中，我们展示了如何利用因果推断的观点使NLP模型更加可信和透明。这两个领域仍处于初期阶段，我们在本文中详细介绍了大量的开放挑战。

因果方法论迫使实践者解释他们的假设。为了提高科学标准，我们认为计算语言学界应该更清楚地了解这些假设，并使用因果推理来分析它们的数据。将我们的语言处理方法推向这个方向，可以使我们更好地理解语言和模型。



机器之心关于论文的介绍：

[NLPer，是时候重视因果推理了！这有一份杨笛一等撰写的综述](https://mp.weixin.qq.com/s/VLmd96_RW-W1_u4BH8tCGQ)



 



